{"cells":[{"cell_type":"markdown","metadata":{"id":"KCqxRM6zTNFC"},"source":["### **Content License Agreement**\n","\n","<font color='red'><b>**WARNING**</b></font> : 본 자료는 삼성청년SW·AI아카데미의 컨텐츠 자산으로, 보안서약서에 의거하여 어떠한 사유로도 임의로 복사, 촬영, 녹음, 복제, 보관, 전송하거나 허가 받지 않은 저장매체를 이용한 보관, 제3자에게 누설, 공개 또는 사용하는 등의 무단 사용 및 불법 배포 시 법적 조치를 받을 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"lbgUPPfQa40C"},"source":["# 과제 목표 (Objectives)\n","\n","## 과제 개요\n","\n","본 과제는 대규모 언어 모델(LLM)을 활용하여 **의도 분류(Intent Classification) 데이터셋을 자동으로 생성**하고, 생성된 데이터셋을 기반으로 **소형 언어 모델(SLM)을 파인튜닝(Fine-tuning)** 하는 전체 워크플로우를 구현하는 것을 목표로 합니다. 이를 통해 데이터 증강(Data Augmentation)부터 모델 경량화 및 특정 태스크 최적화까지의 과정을 직접 경험합니다.\n","\n","## 과제 진행 목적 및 배경\n","\n","* **LLM을 활용한 데이터셋 자동 생성(과제 추가 부분)**: `solar-pro2`와 같은 강력한 LLM을 활용하여 고품질의 의도 분류용 예시 문장을 대량으로 생성합니다. 이를 통해 데이터 구축에 드는 시간과 비용을 절감하는 능력을 기릅니다.\n","* **PEFT(LoRA) 기반 모델 최적화**: HuggingFace의 `SmolLM2-135M-Instruct` 모델에 LoRA(Low-Rank Adaptation) 기법을 적용하여, 적은 양의 학습 가능한 파라미터만으로 특정 분류 태스크(simple/complex)에 대한 성능을 극대화하는 방법을 학습합니다.\n","* **모델 경량화 및 배포 전략 이해**: 대형 모델로 생성한 데이터셋을 기반으로 소형 모델을 파인튜닝함으로써, 실제 서비스 환경에서 효율적으로 동작할 수 있는 경량 모델을 구축하고 배포하는 전략을 탐구합니다.\n","* **엔드투엔드(End-to-End) 파이프라인 구현**: 데이터 생성, 전처리, 모델 훈련, 평가, 그리고 배포용 모델 저장까지의 전 과정을 직접 구현하며 실무적인 MLOps 역량을 강화합니다.\n","\n","## 과제 수행으로 얻어갈 수 있는 역량\n","\n","* **LLM 프롬프트 엔지니어링(과제 추가 부분)**: 특정 형식(JSON)과 내용을 갖춘 데이터를 생성하기 위한 효과적인 프롬프트를 작성하는 능력.\n","* **합성 데이터셋 구축 및 활용**: LLM으로 생성한 합성 데이터(Synthetic Data)를 정제하고, 이를 모델 학습에 효과적으로 활용하는 전략 수립 능력.\n","* **PEFT(Parameter-Efficient Fine-Tuning) 기술**: LoRA를 활용하여 전체 파라미터를 재학습하지 않고도 특정 태스크에 맞게 모델을 효율적으로 튜닝하는 기술.\n","* **HuggingFace 및 PyTorch 활용 능력**: `transformers`, `datasets`, `peft` 등 최신 라이브러리와 PyTorch를 활용하여 모델 훈련 파이프라인을 처음부터 구현하는 능력.\n","\n","## 과제 핵심 내용\n","\n","1.  **데이터셋 생성(과제 추가 부분)**: `SolarChat` LLM을 사용하여 '계정 관리', '주문 결제' 등 6가지 의도(Intent)에 대한 예시 문장과 복잡도(Complexity) 레이블이 포함된 데이터셋을 생성.\n","2.  **모델 및 토크나이저 준비**: `HuggingFaceTB/SmolLM2-135M-Instruct` 모델과 토크나이저를 불러와 시퀀스 분류(Sequence Classification) 태스크에 맞게 설정.\n","3.  **LoRA 적용 및 파인튜닝**: 베이스 모델에 LoRA 설정을 적용하여 학습 가능한 파라미터 수를 최소화하고, 생성된 데이터셋으로 모델을 파인튜닝하여 'suggested_model' (small/large)을 분류하도록 학습.\n","4.  **모델 저장 및 배포 준비**: 학습된 LoRA 어댑터(Adapter)를 저장하고, 필요시 베이스 모델과 병합(merge)하여 추론(Inference)에 바로 사용할 수 있는 형태로 모델을 저장."]},{"cell_type":"markdown","metadata":{"id":"UQlDJGyvyZER"},"source":["# 5-2 챕터의 흐름\n","\n","5-2 챕터: 타겟 디바이스용 모델 준비 및 변환\n","\n","이번 챕터에서는 모델을 타겟 디바이스에 배포할 수 있도록 준비하고, 특정 형식으로 변환하는 과정을 다룹니다.\n","\n","먼저 5-2-1에서는 라우팅 제어에 사용할 플래그를 만들기 위해 데이터셋을 생성하고, 이를 활용해 소형 언어 모델(SLM)을 미세 조정(Fine-Tuning)합니다.\n","\n","이어서 5-2-2에서는 준비된 PyTorch 모델을 TFLite라는 중간 형식으로 변환하는 과정을 학습합니다. 이 과정에서 정적 그래프 변환의 장점을 살펴봅니다. 더 나아가 이 챕터의 핵심은 '왜 최종 변환이 한 번 더 필요한가'를 이해하는 것입니다.\n","\n","각 디바이스의 신경망 실행 엔진은 단순히 언어만 바꾼 것이 아니라, 하드웨어 구조에 맞춰 완전히 별개로 개발된 프레임워크입니다.\n","따라서 자연스레 모든 디바이스에서 작동하는 소스코드는 존재하지 않으며, 각 프레임워크로의 변환 자체만으로도 별도의 긴 태스크가 되는 경우가 많습니다.\n","TFLite로의 변환은 많은 경우 그 최종 변환의 준비가 되며, 최종 변환의 준비과정만으로 5-2-2와 같은 과정이 필요하게 됩니다.\n","해당 과정의 길이와 난이도 상, 이번 3주간의 정규 과정에서 다루기에는 한계가 있어 중간 단계인 TFLite에서 과정을 마무리하게 됩니다.\n","이러한 과정이 있다는 사실을 아는 것을 통해 TFLite 파일을 최종적으로 디바이스별 프레임워크로 다시 변환해야만 하는 이유를 명확히 이해하게 됩니다.\n","\n","차후 확장적으로 목적하는 장치에 맞춰 변환 혹은 LLM 활용을 진행하시기 위해서는, 아래의 링크를 참고해 주세요.\n","\n","타겟 디바이스 별 프레임워크 추가 참고 자료 :\n","\n","Qualcomm - https://docs.qualcomm.com/bundle/publicresource/topics/80-63442-100/how_to_use_genie.html?product=1601111740062489 \\\n","Android - https://ai.google.dev/edge/mediapipe/solutions/genai/llm_inference/index?hl=ko \\\n","Raspberry Pi : Hailo(NPU) - https://hailo.ai/blog/bringing-generative-ai-to-the-edge-llm-on-hailo-10h/ \\\n","Apple - https://machinelearning.apple.com/research/core-ml-on-device-llama \\\n","Arduino - https://docs.m5stack.com/en/stackflow/overview \\\n","BeagleBone - https://docs.beagleboard.org/boards/beaglebone/ai-64/index.html \\\n","Radxa / Rockchips - https://docs.radxa.com/en/rock5/rock5b/app-development/rkllm_install\n","\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KjPTcDo3OxWf","outputId":"cec56d24-7071-4047-dab5-e516e9b62e62","executionInfo":{"status":"ok","timestamp":1761619660945,"user_tz":-540,"elapsed":72742,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain==0.3.27 in /usr/local/lib/python3.12/dist-packages (0.3.27)\n","Collecting langchain-core<1.0.0,>=0.3.72 (from langchain==0.3.27)\n","  Downloading langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.11)\n","Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.1.147)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.11.10)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.0.44)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.32.4)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (6.0.3)\n","Collecting langsmith>=0.1.17 (from langchain==0.3.27)\n","  Downloading langsmith-0.4.38-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (1.33)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (4.15.0)\n","Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (24.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.28.1)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (3.11.3)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.25.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.27) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.27) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.27) (0.4.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.27) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.27) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.27) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.27) (2025.10.5)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.27) (4.11.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.27) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.27) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (3.0.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.27) (1.3.1)\n","Downloading langchain_core-0.3.79-py3-none-any.whl (449 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.8/449.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langsmith-0.4.38-py3-none-any.whl (397 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.3/397.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: langsmith, langchain-core\n","  Attempting uninstall: langsmith\n","    Found existing installation: langsmith 0.1.147\n","    Uninstalling langsmith-0.1.147:\n","      Successfully uninstalled langsmith-0.1.147\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.2.43\n","    Uninstalling langchain-core-0.2.43:\n","      Successfully uninstalled langchain-core-0.2.43\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","langchain-upstage 0.1.7 requires langchain-core<0.3,>=0.2.2, but you have langchain-core 0.3.79 which is incompatible.\n","langchain-openai 0.1.25 requires langchain-core<0.3.0,>=0.2.40, but you have langchain-core 0.3.79 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed langchain-core-0.3.79 langsmith-0.4.38\n","Requirement already satisfied: pymupdf==1.26.3 in /usr/local/lib/python3.12/dist-packages (1.26.3)\n","Requirement already satisfied: koreanize-matplotlib in /usr/local/lib/python3.12/dist-packages (0.1.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from koreanize-matplotlib) (3.10.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->koreanize-matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->koreanize-matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->koreanize-matplotlib) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->koreanize-matplotlib) (1.4.9)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib->koreanize-matplotlib) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->koreanize-matplotlib) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->koreanize-matplotlib) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->koreanize-matplotlib) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->koreanize-matplotlib) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->koreanize-matplotlib) (1.17.0)\n","Requirement already satisfied: datasets==4.0.0 in /usr/local/lib/python3.12/dist-packages (4.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (3.20.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (2.32.4)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (2025.3.0)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (0.35.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (6.0.3)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (3.13.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==4.0.0) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==4.0.0) (1.1.10)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==4.0.0) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==4.0.0) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==4.0.0) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==4.0.0) (2025.10.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.0.0) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.0.0) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.0.0) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==4.0.0) (1.17.0)\n","Requirement already satisfied: trl in /usr/local/lib/python3.12/dist-packages (0.24.0)\n","Requirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from trl) (1.11.0)\n","Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from trl) (4.0.0)\n","Requirement already satisfied: transformers>=4.56.1 in /usr/local/lib/python3.12/dist-packages (from trl) (4.57.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (6.0.3)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (2.8.0+cu126)\n","Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (0.35.3)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (0.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.20.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.32.4)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.1->trl) (2024.11.6)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.1->trl) (0.22.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.13.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (1.1.10)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.10.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.4.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (3.0.3)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.35.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.10)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n","Requirement already satisfied: langchain_upstage in /usr/local/lib/python3.12/dist-packages (0.1.7)\n","Requirement already satisfied: tokenizers==0.22.1 in /usr/local/lib/python3.12/dist-packages (0.22.1)\n","Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers==0.22.1) (0.35.3)\n","Collecting langchain-core<0.3,>=0.2.2 (from langchain_upstage)\n","  Using cached langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n","Requirement already satisfied: langchain-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from langchain_upstage) (0.1.25)\n","Requirement already satisfied: pypdf<5.0.0,>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain_upstage) (4.3.1)\n","Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from langchain_upstage) (2.32.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (3.20.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (2025.3.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (6.0.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (1.1.10)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_upstage) (1.33)\n","Collecting langsmith<0.2.0,>=0.1.112 (from langchain-core<0.3,>=0.2.2->langchain_upstage)\n","  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_upstage) (2.11.10)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_upstage) (8.5.0)\n","Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (1.109.1)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (0.12.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->langchain_upstage) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->langchain_upstage) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->langchain_upstage) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->langchain_upstage) (2025.10.5)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain_upstage) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.2->langchain_upstage) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.2->langchain_upstage) (3.11.3)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.2->langchain_upstage) (1.0.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (4.11.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (0.11.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (1.3.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3,>=0.2.2->langchain_upstage) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3,>=0.2.2->langchain_upstage) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3,>=0.2.2->langchain_upstage) (0.4.2)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai<0.2.0,>=0.1.3->langchain_upstage) (2024.11.6)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.2->langchain_upstage) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.2->langchain_upstage) (0.16.0)\n","Using cached langchain_core-0.2.43-py3-none-any.whl (397 kB)\n","Using cached langsmith-0.1.147-py3-none-any.whl (311 kB)\n","Installing collected packages: langsmith, langchain-core\n","  Attempting uninstall: langsmith\n","    Found existing installation: langsmith 0.4.38\n","    Uninstalling langsmith-0.4.38:\n","      Successfully uninstalled langsmith-0.4.38\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.79\n","    Uninstalling langchain-core-0.3.79:\n","      Successfully uninstalled langchain-core-0.3.79\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","langchain-text-splitters 0.3.11 requires langchain-core<2.0.0,>=0.3.75, but you have langchain-core 0.2.43 which is incompatible.\n","langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 0.2.43 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed langchain-core-0.2.43 langsmith-0.1.147\n"]}],"source":["%pip install langchain==0.3.27\n","%pip install pymupdf==1.26.3\n","%pip install koreanize-matplotlib\n","%pip install datasets==4.0.0\n","%pip install trl\n","%pip install evaluate\n","%pip install langchain_upstage tokenizers==0.22.1\n"]},{"cell_type":"markdown","metadata":{"id":"vsQJjy0Jckk1"},"source":["\n","\n","필요 패키지\n","\n","\n","langchain_upstage\n","\n","langchain  \n","\n","pymupdf  \n","\n","datasets\n","\n","\n","-----\n","\n","## 과제 개요 (Assignment Overview)\n","\n","### 들어가며: LLM을 활용한 데이터셋 구축과 소형 모델 최적화\n","\n","최근 대규모 언어 모델(LLM)의 발전으로 고품질의 텍스트 데이터를 프로그래밍 방식으로 생성하는 것이 가능해졌습니다. 이러한 **합성 데이터셋(Synthetic Dataset)**은 특정 태스크에 맞는 학습 데이터를 구하기 어려운 경우 매우 효과적인 대안이 됩니다.\n","\n","본 과제에서는 LLM을 활용하여 **의도 분류(Intent Classification)**를 위한 데이터셋을 자동으로 생성하고, 생성된 데이터로 특정 목적에 맞게 경량화된 **소형 언어 모델(SLM)**을 **PEFT(Parameter-Efficient Fine-Tuning)** 방식으로 튜닝하는 엔드투엔드(End-to-End) 파이프라인을 구현합니다.\n","\n","### 과제 목차 (Table of Contents)\n","\n","이 노트북은 네 가지 주요 파트로 구성되어 있습니다.\n","\n","1.  **LLM을 이용한 의도 분류 데이터셋 생성**\n","\n","      * `Solar` LLM에 특정 프롬프트를 입력하여, 사전 정의된 의도(Intent) 레이블과 복잡도(Complexity)를 포함하는 학습용 문장 데이터셋을 JSON 형식으로 생성합니다.\n","\n","2.  **데이터셋 전처리 및 준비**\n","\n","      * 생성된 데이터를 `pandas`와 `datasets` 라이브러리를 이용해 불러오고, 모델 학습에 적합한 형태로 변환합니다. 전체 데이터를 학습(Train), 검증(Validation), 테스트(Test)용으로 분할합니다.\n","\n","3.  **PEFT(LoRA)를 적용한 모델 미세조정**\n","\n","      * `HuggingFaceTB/SmolLM2-135M-Instruct` 모델을 기반으로, LoRA(Low-Rank Adaptation) 기법을 적용하여 적은 비용으로 효율적인 미세조정을 진행합니다. 문장의 복잡도에 따라 적절한 모델(small/large)을 추천하도록 분류 모델을 학습시킵니다.\n","\n","4.  **모델 저장 및 배포 준비**\n","\n","      * 학습이 완료된 모델의 LoRA 가중치(Adapter)를 저장합니다. 필요시, 베이스 모델과 가중치를 병합(merge)하여 추론 환경에 바로 배포할 수 있는 형태로 만듭니다."]},{"cell_type":"markdown","metadata":{"id":"o0x_J_DUliyN"},"source":["# 01. 의도 분류 데이터셋 구축 (실습에 추가된 내용)"]},{"cell_type":"markdown","metadata":{"id":"o38SErc6jE6K"},"source":["### 라이브러리 임포트 및 버전 확인\n","설치된 라이브러리를 임포트하고, 각 라이브러리의 버전을 출력하여 개발 환경의 재현성을 확보합니다. 이는 협업 및 디버깅 과정에서 발생할 수 있는 잠재적 호환성 문제를 예방하는 데 중요합니다."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nex0FpraPYPo","outputId":"221644a3-fe62-44fc-b910-9ba39abb2c32","executionInfo":{"status":"ok","timestamp":1761619673904,"user_tz":-540,"elapsed":12945,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["langchain  ==  0.3.27\n","pymupdf  ==  1.26.3\n","datasets  ==  4.0.0\n"]}],"source":["import langchain\n","import pymupdf\n","import koreanize_matplotlib\n","import datasets\n","from trl import SFTConfig, SFTTrainer, setup_chat_format\n","\n","def print_version(lib):\n","    print(lib.__name__, \" == \", lib.__version__)\n","\n","print_version(langchain)\n","print_version(pymupdf)\n","print_version(datasets)"]},{"cell_type":"markdown","metadata":{"id":"rh8-K_ISjGqp"},"source":["### LLM (Large Language Model) 초기화\n","데이터셋 생성을 위해 Upstage사의 solar-pro2 모델을 LangChain 프레임워크를 통해 초기화합니다. API 키는 보안을 위해 환경 변수 또는 Colab의 userdata 기능을 통해 안전하게 로드합니다. LLM 인스턴스는 이후 데이터 생성 프롬프트에 대한 응답을 생성하는 데 사용됩니다."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"LsyIe15dPh5m","executionInfo":{"status":"ok","timestamp":1761619675692,"user_tz":-540,"elapsed":1786,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"outputs":[],"source":["import os\n","import json\n","import argparse\n","from typing import List, Dict\n","from pathlib import Path\n","import random\n","import csv\n","import torch\n","from langchain_upstage import ChatUpstage\n","\n","\n","try:\n","    api_key = 'up_8Wp21SIv4bjbx04Cb1FEyglr1noEN'\n","    os.environ[\"SOLAR_API_KEY\"] = api_key\n","except Exception:\n","    # Colab이 아니면 이미 환경변수로 설정되어 있다고 가정합니다.\n","    print(\"failed to load llm, \", Exception)\n","\n","# SolarChat 초기화(사용자 제공 코드 기반)\n","try:\n","    llm= ChatUpstage(\n","        model=\"solar-pro2\",\n","        temperature=0.2,\n","        api_key = api_key\n","    )\n","    HAVE_LLM = True\n","except Exception:\n","    # Solar 패키지가 설치되어 있지 않거나 Colab 환경이 아니면 LLM 자동 생성은 불가합니다.\n","    raise Exception(\"Could not load LLM, please retry.\")\n","    llm = None\n","    HAVE_LLM = False\n"]},{"cell_type":"markdown","metadata":{"id":"U59ArVCbjI8O"},"source":["### 데이터 생성 파라미터 정의\n","데이터셋 생성에 필요한 핵심 파라미터를 정의합니다. MACRO_INTENTS는 생성할 데이터의 최상위 의도(Intent) 카테고리를 목록화한 것입니다. DEFAULT_ROUTER는 각 의도의 기본 복잡도를 설정하여, 추후 생성될 문장의 suggested_model 레이블을 결정하는 규칙으로 사용됩니다. SAMPLE_TEMPLATES는 LLM 사용이 불가능할 경우를 대비한 대체 데이터 생성용 템플릿입니다."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"5oBsBuR1PyAA","executionInfo":{"status":"ok","timestamp":1761619683905,"user_tz":-540,"elapsed":37,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"outputs":[],"source":["\n","# --- 사용자 정의: Macro-Intent 목록 ---\n","MACRO_INTENTS = [\n","    \"계정_관리\",        # 계정 생성/로그인/비밀번호 등\n","    \"주문_결제\",        # 주문, 결제 수단, 결제 실패\n","    \"배송_문의\",        # 배송상태, 배송기간, 추적\n","    \"상품_정보\",        # 상품 상세, 재고, 옵션\n","    \"기술_지원\",        # 오류, 기능문의, 사용법\n","    \"반품_환불\",        # 반품절차, 환불요청\n","]\n","\n","# 라우팅 기준: simple -> small model, complex -> large model\n","# 여기서는 각 Intent에 대해 기본 권장 모델을 지정할 수 있습니다.\n","DEFAULT_ROUTER = {\n","    # Intent: \"simple_by_default\" (True면 일반적으로 소형모델로 처리 가능)\n","    \"계정_관리\": True,\n","    \"주문_결제\": False,\n","    \"배송_문의\": True,\n","    \"상품_정보\": True,\n","    \"기술_지원\": False,\n","    \"반품_환불\": False,\n","}\n","\n","# 샘플 문장(LLM이 없을 경우를 대비한 간단한 템플릿 예시)\n","SAMPLE_TEMPLATES = {\n","    \"계정_관리\": [\n","        \"비밀번호를 잊어버렸어요. 어떻게 재설정하나요?\",\n","        \"회원 탈퇴하려면 어떻게 해야 하나요?\",\n","        \"이메일을 변경하고 싶습니다.\"\n","    ],\n","    \"주문_결제\": [\n","        \"주문 결제 오류가 발생했어요.\",\n","        \"카드로 결제하려는데 실패합니다.\",\n","        \"쿠폰 적용은 어디서 하나요?\"\n","    ],\n","    \"배송_문의\": [\n","        \"내 주문 배송 상태를 알려주세요.\",\n","        \"택배사와 운송장 번호를 알고 싶어요.\",\n","        \"배송이 지연되고 있습니다.\"\n","    ],\n","    \"상품_정보\": [\n","        \"이 제품의 사이즈는 어떻게 되나요?\",\n","        \"재고가 언제 들어오나요?\",\n","        \"상품 상세 설명을 보여주세요.\"\n","    ],\n","    \"기술_지원\": [\n","        \"앱이 계속 충돌합니다. 로그를 어디서 확인하나요?\",\n","        \"API 호출 시 500 에러가 납니다.\",\n","        \"SDK 설치 방법을 알려주세요.\"\n","    ],\n","    \"반품_환불\": [\n","        \"반품 신청은 어떻게 하나요?\",\n","        \"환불 처리는 얼마나 걸리나요?\",\n","        \"상품이 불량인데 교환 가능한가요?\"\n","    ]\n","}"]},{"cell_type":"markdown","metadata":{"id":"l0n-MafpjLrL"},"source":["### LLM을 이용한 발화(Utterance) 생성 함수\n","LLM을 호출하여 특정 의도(Intent)에 해당하는 예시 문장들을 생성하는 함수 llm_generate_utterances를 정의합니다. 이 함수는 LLM에게 JSON 배열 형식으로 응답을 요청하는 프롬프트를 구성하고, 반환된 텍스트를 파싱하여 {'text': ..., 'complexity': ...} 형태의 딕셔너리 리스트로 반환합니다. LLM 호출 실패 시에는 사전에 정의된 SAMPLE_TEMPLATES를 활용하는 예외 처리 로직을 포함합니다."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"EecQ6zElP037","executionInfo":{"status":"ok","timestamp":1761619697179,"user_tz":-540,"elapsed":18,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"outputs":[],"source":["\n","def llm_generate_utterances(intent: str, n: int = 100) -> List[Dict]:\n","    \"\"\"\n","    LLM을 사용해 intent별로 예문을 생성합니다.\n","    반환 형식: List of dicts: {\"text\":..., \"complexity\": \"simple\"/\"complex\"}\n","    프롬프트는 LLM에게 JSONL 형식으로 결과를 달라고 요청합니다.\n","    \"\"\"\n","    if not HAVE_LLM:\n","        # LLM이 없을 때는 템플릿 기반으로 변형을 만들어 리턴합니다.\n","        templates = SAMPLE_TEMPLATES.get(intent, [f\"{intent} 관련 문의입니다.\"])\n","        res = []\n","        for i in range(n):\n","            base = random.choice(templates)\n","            # 간단한 변형: 접속사나 추가정보 삽입\n","            if i % 5 == 0:\n","                text = base + \" 자세히 설명해주세요.\"\n","                complexity = \"complex\"\n","            else:\n","                text = base\n","                complexity = \"simple\"\n","            res.append({\"text\": text, \"complexity\": complexity})\n","        return res\n","\n","    # LLM이 사용 가능한 경우\n","    # hint. \"아래의 Parsing을 통과할 수 있도록, 문제에서 주어진 \"형식\"에 집중하여 프롬프팅 해주세요.\n","    # hint. fstring을 사용하시면 갯수와 주제에 맞게 동적으로 프롬프팅하실 수 있습니다.\n","    # 예시는 답이 될 수 있는 하나일 뿐이고, 구동 시 확인하실 수 있다 시피 이 답 또한 생성 성공 100%를 보장하지 않습니다.\n","    # 만족하실만한 결과물이 나온다면 충분합니다.\n","    # [START CODE]\n","    prompt = (\n","        f\"다음은 고객 문의의 대주제(Macro-Intent) '{intent}'에 해당하는 실제 사용자가 말할 법한 예시 문장 {n} 개를\"\n","        \"JSON 배열로 생성해 주세요. 각 항목은 'text'와 'complexity' 필드를 가지며,\"\n","        \"'complexity'는 'simple' 또는 'complex' 중 하나로 표기하세요.\\n\"\n","        \"예: [{\\\"text\\\": \\\"...\\\", \\\"complexity\\\": \\\"simple\\\"}, ...]\"\n","        \"위 형식에 어긋나는 출력은 출력에서 제외합니다.\"\n","    )\n","    try:\n","        raw = llm.invoke(prompt)\n","        # llm.invoke의 반환 형식은 환경에 따라 다르므로 문자열로 가정\n","        if isinstance(raw, dict):\n","            # 경우에 따라 바로 파싱된 구조가 올 수 있음\n","            out = raw\n","        else:\n","            out = raw\n","        # 문자열이면 JSON 파싱 시도\n","        if isinstance(out.content, str):\n","            out_content = out.content\n","            out_content = out_content.strip()\n","            # sometimes model returns wrapped in ```json``` fences\n","            if out_content.startswith('```'):\n","                # 간단한 정제\n","                out_content = '\\n'.join(out_content.splitlines()[1:-1])\n","            # parse\n","            parsed = json.loads(out_content)\n","        else:\n","            parsed = out\n","        # validation\n","        results = []\n","        for item in parsed:\n","            t = item.get('text') if isinstance(item, dict) else None\n","            c = item.get('complexity') if isinstance(item, dict) else 'simple'\n","            if t:\n","                results.append({'text': t, 'complexity': c})\n","        # 보장: required n items\n","        if len(results) < n:\n","            # 간단 보충 (중복 변형)\n","            while len(results) < n:\n","                pick = random.choice(results) if results else {\"text\": f\"{intent} 관련 문의입니다.\", \"complexity\": \"simple\"}\n","                results.append({\"text\": pick['text'] + \"\", \"complexity\": pick['complexity']})\n","        return results[:n]\n","    except Exception as e:\n","        print(\"LLM 생성 중 오류 발생, 템플릿 기반으로 대체합니다.\", e)\n","        return llm_generate_utterances(intent, n)"]},{"cell_type":"markdown","metadata":{"id":"e8mK5sLgjS8k"},"source":["### 추천 모델 할당 로직 정의\n","생성된 문장의 의도와 복잡도를 기반으로 small 또는 large 모델을 추천하는 로직을 함수로 정의합니다. 이 함수는 DEFAULT_ROUTER 규칙을 참조하여, 복잡도가 complex인 경우는 항상 large 모델을, 그렇지 않은 경우는 기본 설정에 따라 모델을 할당합니다."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"XBxAxlvLQK24","executionInfo":{"status":"ok","timestamp":1761619755951,"user_tz":-540,"elapsed":11,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"outputs":[],"source":["# 문제 2: 문장의 의도(intent)와 복잡도(complexity)에 따라 추천 모델('small' 또는 'large')을 할당하는 로직을 구현합니다.\n","# 'complexity'가 'complex'이면 항상 'large'를 반환해야 합니다.\n","# 그렇지 않은 경우, DEFAULT_ROUTER 딕셔너리를 참조하여 모델을 결정합니다.\n","\n","def assign_suggested_model(intent: str, complexity: str) -> str:\n","    \"\"\"기본 라우팅 규칙에 따라 suggested_model을 결정합니다.\"\"\"\n","    base_small = DEFAULT_ROUTER.get(intent, True)\n","    # 복잡한 문장은 대형 모델 권장\n","    if complexity == 'complex':\n","        return 'large'\n","    return 'small' if base_small else 'large'"]},{"cell_type":"markdown","metadata":{"id":"g-n0Cfz8jVDb"},"source":["### 전체 데이터셋 구축 파이프라인\n","앞서 정의한 함수들을 조합하여 전체 합성 데이터셋을 구축하는 build_dataset 함수를 정의합니다. 이 함수는 정의된 모든 MACRO_INTENTS에 대해 반복적으로 llm_generate_utterances를 호출하고, 각 결과에 assign_suggested_model을 적용하여 최종 레코드를 생성합니다. 생성된 데이터는 중복 제거 후 CSV 및 JSONL 파일 형식으로 저장됩니다. 이 과정은 데이터 생성부터 최종 파일 직렬화(Serialization)까지의 전체 파이프라인 역할을 합니다."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"lfHU026TQOhC","executionInfo":{"status":"ok","timestamp":1761619756591,"user_tz":-540,"elapsed":19,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"outputs":[],"source":["from pathlib import Path\n","import csv, json\n","from typing import List\n","\n","def build_dataset(intents: List[str], per_intent: int = 100, batch_size: int = 10, out_dir: str = 'output_dataset') -> Path:\n","    \"\"\"\n","    intents: 생성할 intent 목록\n","    per_intent: intent당 최종 생성 개수\n","    batch_size: 한 번에 LLM에 요청할 문장 수\n","    out_dir: 저장 폴더\n","    \"\"\"\n","    out_path = Path(out_dir)\n","    out_path.mkdir(parents=True, exist_ok=True)\n","    records = []\n","\n","    for intent in intents:\n","        print(f\"Generating for intent: {intent} (target count={per_intent})\")\n","        generated_count = 0\n","        while generated_count < per_intent:\n","            current_batch = min(batch_size, per_intent - generated_count)\n","            examples = llm_generate_utterances(intent, n=current_batch)\n","            for ex in examples:\n","                text = ex.get('text')\n","                complexity = ex.get('complexity', 'simple')\n","                suggested_model = assign_suggested_model(intent, complexity)\n","                records.append({\n","                    'intent': intent,\n","                    'text': text,\n","                    'complexity': complexity,\n","                    'suggested_model': suggested_model\n","                })\n","            generated_count += current_batch\n","            print(f\"  Generated so far: {generated_count}/{per_intent}\")\n","\n","    # 중복 제거\n","    unique_texts = set()\n","    deduped = []\n","    for r in records:\n","        key = (r['intent'], r['text'])\n","        if key not in unique_texts:\n","            unique_texts.add(key)\n","            deduped.append(r)\n","\n","    # 저장: CSV 및 JSONL\n","    csv_file = out_path / 'intent_dataset.csv'\n","    jsonl_file = out_path / 'intent_dataset.jsonl'\n","    with open(csv_file, 'w', newline='', encoding='utf-8') as f:\n","        writer = csv.DictWriter(f, fieldnames=['intent', 'text', 'complexity', 'suggested_model'])\n","        writer.writeheader()\n","        for r in deduped:\n","            writer.writerow(r)\n","\n","    with open(jsonl_file, 'w', encoding='utf-8') as f:\n","        for r in deduped:\n","            f.write(json.dumps(r, ensure_ascii=False) + '\\n')\n","\n","    print(f\"Saved {len(deduped)} examples -> {csv_file}, {jsonl_file}\")\n","    return out_path\n"]},{"cell_type":"markdown","metadata":{"id":"weW8qlMvjX9F"},"source":["### 데이터셋 생성 실행\n","정의된 build_dataset 함수를 실행하여 실제 데이터셋 생성을 시작합니다. PER_INTENT 변수는 각 의도당 생성할 문장의 수를 지정합니다. 파일이 이미 존재하는 경우, 생성 과정을 건너뛰도록 조건문이 설정되어 있습니다."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"M_qIAnijQQbY","executionInfo":{"status":"ok","timestamp":1761619931106,"user_tz":-540,"elapsed":172469,"user":{"displayName":"S H","userId":"07486973781233731858"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"954eb7bd-2ab9-4320-f617-ccdf35b5c1b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generating for intent: 계정_관리 (target count=100)\n","  Generated so far: 10/100\n","  Generated so far: 20/100\n","  Generated so far: 30/100\n","  Generated so far: 40/100\n","  Generated so far: 50/100\n","  Generated so far: 60/100\n","  Generated so far: 70/100\n","  Generated so far: 80/100\n","  Generated so far: 90/100\n","  Generated so far: 100/100\n","Generating for intent: 주문_결제 (target count=100)\n","  Generated so far: 10/100\n","  Generated so far: 20/100\n","  Generated so far: 30/100\n","  Generated so far: 40/100\n","  Generated so far: 50/100\n","  Generated so far: 60/100\n","  Generated so far: 70/100\n","  Generated so far: 80/100\n","  Generated so far: 90/100\n","  Generated so far: 100/100\n","Generating for intent: 배송_문의 (target count=100)\n","  Generated so far: 10/100\n","  Generated so far: 20/100\n","  Generated so far: 30/100\n","  Generated so far: 40/100\n","  Generated so far: 50/100\n","  Generated so far: 60/100\n","  Generated so far: 70/100\n","  Generated so far: 80/100\n","  Generated so far: 90/100\n","  Generated so far: 100/100\n","Generating for intent: 상품_정보 (target count=100)\n","  Generated so far: 10/100\n","  Generated so far: 20/100\n","  Generated so far: 30/100\n","  Generated so far: 40/100\n","  Generated so far: 50/100\n","  Generated so far: 60/100\n","  Generated so far: 70/100\n","  Generated so far: 80/100\n","  Generated so far: 90/100\n","  Generated so far: 100/100\n","Generating for intent: 기술_지원 (target count=100)\n","  Generated so far: 10/100\n","  Generated so far: 20/100\n","  Generated so far: 30/100\n","  Generated so far: 40/100\n","  Generated so far: 50/100\n","  Generated so far: 60/100\n","  Generated so far: 70/100\n","  Generated so far: 80/100\n","  Generated so far: 90/100\n","  Generated so far: 100/100\n","Generating for intent: 반품_환불 (target count=100)\n","  Generated so far: 10/100\n","  Generated so far: 20/100\n","  Generated so far: 30/100\n","  Generated so far: 40/100\n","  Generated so far: 50/100\n","  Generated so far: 60/100\n","  Generated so far: 70/100\n","  Generated so far: 80/100\n","  Generated so far: 90/100\n","  Generated so far: 100/100\n","Saved 454 examples -> intent_dataset.csv, intent_dataset.jsonl\n"]}],"source":["\n","INTENTS = MACRO_INTENTS\n","PER_INTENT = 100\n","OUT_DIR = './'\n","# if certain path exists\n","if not os.path.exists('./intent_dataset.csv'):\n","    build_dataset(INTENTS, per_intent=PER_INTENT, out_dir=OUT_DIR)"]},{"cell_type":"markdown","metadata":{"id":"dp7Ji_qWjaGi"},"source":["### 생성된 데이터 확인\n","생성된 CSV 파일을 pandas DataFrame으로 로드하여 상위 10개 행을 출력하고, 총 데이터 수를 확인합니다. 이를 통해 데이터가 의도한 형식과 내용으로 정상적으로 생성되었는지 검증합니다. 또한, JSONL 파일의 내용도 일부 출력하여 형식을 확인합니다."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"An8ZOHb-Q4zP","executionInfo":{"status":"ok","timestamp":1761619931195,"user_tz":-540,"elapsed":68,"user":{"displayName":"S H","userId":"07486973781233731858"}},"colab":{"base_uri":"https://localhost:8080/","height":536},"outputId":"934cb451-2948-4341-cc8e-cf3895173fb3"},"outputs":[{"output_type":"stream","name":"stdout","text":["CSV 존재 여부: True\n"]},{"output_type":"display_data","data":{"text/plain":["  intent                                 text complexity suggested_model\n","0  계정_관리                 내 계정 비밀번호를 변경하고 싶어요.     simple           small\n","1  계정_관리            계정을 완전히 삭제하려면 어떻게 해야 하나요?     simple           small\n","2  계정_관리              2단계 인증을 설정하는 방법을 알려주세요.     simple           small\n","3  계정_관리  로그인 시 '계정 정지' 메시지가 나오는데 해결 방법이 있나요?    complex           large\n","4  계정_관리           가족 계정을 추가하려면 어떤 절차가 필요한가요?    complex           large\n","5  계정_관리   해외에서 로그인 시도가 감지되었는데, 보안 조치가 가능한가요?    complex           large\n","6  계정_관리         계정 복구 이메일을 변경하려면 어떻게 해야 하나요?     simple           small\n","7  계정_관리          연동된 SNS 계정을 해제하는 방법을 모르겠어요.     simple           small\n","8  계정_관리      계정 활동 내역을 확인하고 의심스러운 로그를 신고하려면?    complex           large\n","9  계정_관리        결제 수단 정보를 업데이트하려면 어디로 가야 하나요?     simple           small"],"text/html":["\n","  <div id=\"df-5b258beb-7802-43c1-9158-89290cfaa945\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>intent</th>\n","      <th>text</th>\n","      <th>complexity</th>\n","      <th>suggested_model</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>계정_관리</td>\n","      <td>내 계정 비밀번호를 변경하고 싶어요.</td>\n","      <td>simple</td>\n","      <td>small</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>계정_관리</td>\n","      <td>계정을 완전히 삭제하려면 어떻게 해야 하나요?</td>\n","      <td>simple</td>\n","      <td>small</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>계정_관리</td>\n","      <td>2단계 인증을 설정하는 방법을 알려주세요.</td>\n","      <td>simple</td>\n","      <td>small</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>계정_관리</td>\n","      <td>로그인 시 '계정 정지' 메시지가 나오는데 해결 방법이 있나요?</td>\n","      <td>complex</td>\n","      <td>large</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>계정_관리</td>\n","      <td>가족 계정을 추가하려면 어떤 절차가 필요한가요?</td>\n","      <td>complex</td>\n","      <td>large</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>계정_관리</td>\n","      <td>해외에서 로그인 시도가 감지되었는데, 보안 조치가 가능한가요?</td>\n","      <td>complex</td>\n","      <td>large</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>계정_관리</td>\n","      <td>계정 복구 이메일을 변경하려면 어떻게 해야 하나요?</td>\n","      <td>simple</td>\n","      <td>small</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>계정_관리</td>\n","      <td>연동된 SNS 계정을 해제하는 방법을 모르겠어요.</td>\n","      <td>simple</td>\n","      <td>small</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>계정_관리</td>\n","      <td>계정 활동 내역을 확인하고 의심스러운 로그를 신고하려면?</td>\n","      <td>complex</td>\n","      <td>large</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>계정_관리</td>\n","      <td>결제 수단 정보를 업데이트하려면 어디로 가야 하나요?</td>\n","      <td>simple</td>\n","      <td>small</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b258beb-7802-43c1-9158-89290cfaa945')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5b258beb-7802-43c1-9158-89290cfaa945 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5b258beb-7802-43c1-9158-89290cfaa945');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-396dba01-16d1-430f-83ed-6305a04b18ec\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-396dba01-16d1-430f-83ed-6305a04b18ec')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-396dba01-16d1-430f-83ed-6305a04b18ec button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"    print(\\\"\\ucd1d JSONL \\ub77c\\uc778 \\uc218:\\\", len(lines))\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"intent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\uacc4\\uc815_\\uad00\\ub9ac\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\uacc4\\uc815 \\ud65c\\ub3d9 \\ub0b4\\uc5ed\\uc744 \\ud655\\uc778\\ud558\\uace0 \\uc758\\uc2ec\\uc2a4\\ub7ec\\uc6b4 \\ub85c\\uadf8\\ub97c \\uc2e0\\uace0\\ud558\\ub824\\uba74?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"complexity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"complex\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"suggested_model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"large\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["총 행 수: 454\n","JSONL 샘플 (최초 5줄):\n","{\"intent\": \"계정_관리\", \"text\": \"내 계정 비밀번호를 변경하고 싶어요.\", \"complexity\": \"simple\", \"suggested_model\": \"small\"}\n","{\"intent\": \"계정_관리\", \"text\": \"계정을 완전히 삭제하려면 어떻게 해야 하나요?\", \"complexity\": \"simple\", \"suggested_model\": \"small\"}\n","{\"intent\": \"계정_관리\", \"text\": \"2단계 인증을 설정하는 방법을 알려주세요.\", \"complexity\": \"simple\", \"suggested_model\": \"small\"}\n","{\"intent\": \"계정_관리\", \"text\": \"로그인 시 '계정 정지' 메시지가 나오는데 해결 방법이 있나요?\", \"complexity\": \"complex\", \"suggested_model\": \"large\"}\n","{\"intent\": \"계정_관리\", \"text\": \"가족 계정을 추가하려면 어떤 절차가 필요한가요?\", \"complexity\": \"complex\", \"suggested_model\": \"large\"}\n","\n","총 JSONL 라인 수: 454\n"]}],"source":["# 셀 5: 생성된 CSV/JSONL 파일을 확인하고 간단히 미리보기\n","import pandas as pd\n","csv_path = \"intent_dataset.csv\"\n","jsonl_path = \"intent_dataset.jsonl\"\n","\n","\n","print(\"CSV 존재 여부:\", bool(pd.io.common.file_exists(csv_path)))\n","if pd.io.common.file_exists(csv_path):\n","    df = pd.read_csv(csv_path)\n","    display(df.head(10))\n","    print(\"총 행 수:\", len(df))\n","\n","# JSONL도 확인\n","if pd.io.common.file_exists(jsonl_path):\n","    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n","        lines = f.readlines()\n","    print(\"JSONL 샘플 (최초 5줄):\")\n","    print(\"\".join(lines[:5]))\n","    print(\"총 JSONL 라인 수:\", len(lines))"]},{"cell_type":"markdown","metadata":{"id":"T0kVr-MOjhCO"},"source":["### 데이터셋 로컬 다운로드 (선택 사항)\n","Google Colab 환경에서 생성된 데이터셋 파일(intent_dataset.csv, intent_dataset.jsonl)을 로컬 머신으로 다운로드하는 코드입니다. 이 단계는 백업 또는 다른 환경에서의 추가 분석을 위해 선택적으로 실행할 수 있습니다."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"cPCPkF6UnOyC","executionInfo":{"status":"ok","timestamp":1761620146290,"user_tz":-540,"elapsed":20896,"user":{"displayName":"S H","userId":"07486973781233731858"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8930a102-88b6-42ca-e8b3-1236d506d228"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"FxP-l1y5RATi","colab":{"base_uri":"https://localhost:8080/","height":245},"executionInfo":{"status":"error","timestamp":1761620304646,"user_tz":-540,"elapsed":92,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"0afab406-9b38-46a4-c231-7ef93ca8c62d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_0385ee20-b310-4c3c-8eeb-cee52e407bd2\", \"intent_dataset.csv\", 49178)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_76ca3d27-c5b4-48ef-b833-cf210666308c\", \"intent_dataset.jsonl\", 77666)"]},"metadata":{}},{"output_type":"error","ename":"OSError","evalue":"[Errno 95] Operation not supported: '/content/drive/intent_classification_dataset'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2841195017.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Google Drive가 마운트되어 있어야 합니다. (이전 셀에서 마운트)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdrive_dataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/intent_classification_dataset\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_dataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# 파일 복사\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 95] Operation not supported: '/content/drive/intent_classification_dataset'"]}],"source":["# 셀 6: 생성된 파일을 로컬로 다운로드\n","from google.colab import files\n","import os\n","import shutil\n","\n","# 로컬 다운로드 (선택 사항)\n","files.download('intent_dataset.csv')\n","files.download('intent_dataset.jsonl')\n","\n","# Google Drive에 저장\n","\n","# Google Drive가 마운트되어 있어야 합니다. (이전 셀에서 마운트)\n","drive_dataset_path = \"/content/drive/intent_classification_dataset\"\n","os.makedirs(drive_dataset_path, exist_ok=True)\n","\n","# 파일 복사\n","csv_path = \"intent_dataset.csv\"\n","jsonl_path = \"intent_dataset.jsonl\"\n","\n","if os.path.exists(csv_path):\n","    shutil.copy(csv_path, drive_dataset_path)\n","    print(f\"Copied {csv_path} to {drive_dataset_path}\")\n","\n","if os.path.exists(jsonl_path):\n","    shutil.copy(jsonl_path, drive_dataset_path)\n","    print(f\"Copied {jsonl_path} to {drive_dataset_path}\")\n","\n","print(f\"Dataset files saved to Google Drive: {drive_dataset_path}\")"]},{"cell_type":"markdown","metadata":{"id":"M46ZbhMxTgJg"},"source":["# 02. 생성 데이터셋을 활용한 PEFT 활용 모델 Fine-Tuning\n","이번 세션에서 사용할 모델은 Smollm2-135m으로, 본래 SequenceClassification을 위한 가중치가 존재하지 않습니다. 이에 이렇게 불러오는 모델의 끝단은 초기화된 가중치를 가진 Score 레이어가 존재하게 되며, 이번 훈련에서 해당 레이어를 포함한 다른 Linear 레이어들을 LoRA를 활용해 훈련합니다.\n","\n","### 모델 훈련을 위한 라이브러리 임포트\n","모델 미세조정(Fine-tuning)에 필요한 라이브러리들을 임포트합니다. sklearn은 데이터 분할, torch는 딥러닝 모델의 기반, transformers는 사전 학습된 모델과 토크나이저를 로드하기 위해 사용됩니다. peft 라이브러리는 LoRA와 같은 파라미터 효율적 미세조정 기법을 적용하기 위해 필요합니다. 재현성을 위해 시드(SEED) 값을 고정합니다."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"cgh2KxR7TmPx","executionInfo":{"status":"ok","timestamp":1761620315095,"user_tz":-540,"elapsed":3,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"outputs":[],"source":["# 셀 2: 기본 임포트 및 설정\n","import os\n","import random\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import torch\n","from datasets import Dataset, DatasetDict\n","\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    TrainingArguments,\n","    Trainer,\n","    DataCollatorWithPadding,\n","    TrainerCallback,\n",")\n","\n","# 재현성\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n","\n","model_name = \"HuggingFaceTB/SmolLM2-135M-Instruct\""]},{"cell_type":"markdown","metadata":{"id":"JHXoDqIsj3mK"},"source":[]},{"cell_type":"code","execution_count":24,"metadata":{"id":"WgeQnK3mTwQd","executionInfo":{"status":"ok","timestamp":1761620316278,"user_tz":-540,"elapsed":5,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"outputs":[],"source":["import os, random, numpy as np, pandas as pd\n","from datasets import Dataset, DatasetDict\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n","from peft import LoraConfig, get_peft_model, PeftModel\n","\n","# reproducibility\n","SEED = 42\n","random.seed(SEED); np.random.seed(SEED); os.environ[\"PYTHONHASHSEED\"]=str(SEED)\n","\n","# 유틸: 모델의 모듈 이름들을 출력/검색해서 LoRA 타겟 후보를 추천\n","def list_module_names(model, max_items=200):\n","    names = []\n","    for n, m in model.named_modules():\n","        names.append(n)\n","    # 상위 일부만 출력\n","    print(\"=== first 200 module names (truncated) ===\")\n","    for i, nm in enumerate(names[:max_items]):\n","        print(i, nm)\n","    return names\n","\n","def suggest_target_modules_from_names(names):\n","    # 흔히 사용하는 키워드 기반 추천\n","    candidates = set()\n","    keywords = [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"q\",\"k\",\"v\",\"gate\",\"down_proj\",\"up_proj\",\"dense\",\"proj\",\"wq\",\"wk\",\"wv\",\"wo\",\"attn\"]\n","    for nm in names:\n","        for kw in keywords:\n","            if kw in nm:\n","                candidates.add(nm.split('.')[-1])  # 마지막 파트 기준으로 제안\n","    # 정렬/중복 제거\n","    return sorted(list(candidates))[:20]\n"]},{"cell_type":"markdown","metadata":{"id":"a4Hkf4naj595"},"source":["### 학습 데이터 로드 및 레이블 인코딩\n","앞서 생성한 intent_dataset.csv 파일을 pandas DataFrame으로 로드합니다. 훈련 태스크의 목표 변수(target variable)인 suggested_model 컬럼의 텍스트 레이블('small', 'large')을 모델이 이해할 수 있도록 숫자(0, 1)로 변환하는 label2id 및 id2label 맵을 정의합니다.\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"id":"8VNuj5c4aLVV","outputId":"f174fe03-6cbf-45af-fee6-e2d128a6c39c","executionInfo":{"status":"ok","timestamp":1761619974398,"user_tz":-540,"elapsed":36,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["loaded 454 rows; sample:\n"]},{"output_type":"display_data","data":{"text/plain":["  intent                                 text complexity suggested_model\n","0  계정_관리                 내 계정 비밀번호를 변경하고 싶어요.     simple           small\n","1  계정_관리            계정을 완전히 삭제하려면 어떻게 해야 하나요?     simple           small\n","2  계정_관리              2단계 인증을 설정하는 방법을 알려주세요.     simple           small\n","3  계정_관리  로그인 시 '계정 정지' 메시지가 나오는데 해결 방법이 있나요?    complex           large\n","4  계정_관리           가족 계정을 추가하려면 어떤 절차가 필요한가요?    complex           large"],"text/html":["\n","  <div id=\"df-4125722a-ee7b-4c90-955c-c392576d2500\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>intent</th>\n","      <th>text</th>\n","      <th>complexity</th>\n","      <th>suggested_model</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>계정_관리</td>\n","      <td>내 계정 비밀번호를 변경하고 싶어요.</td>\n","      <td>simple</td>\n","      <td>small</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>계정_관리</td>\n","      <td>계정을 완전히 삭제하려면 어떻게 해야 하나요?</td>\n","      <td>simple</td>\n","      <td>small</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>계정_관리</td>\n","      <td>2단계 인증을 설정하는 방법을 알려주세요.</td>\n","      <td>simple</td>\n","      <td>small</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>계정_관리</td>\n","      <td>로그인 시 '계정 정지' 메시지가 나오는데 해결 방법이 있나요?</td>\n","      <td>complex</td>\n","      <td>large</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>계정_관리</td>\n","      <td>가족 계정을 추가하려면 어떤 절차가 필요한가요?</td>\n","      <td>complex</td>\n","      <td>large</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4125722a-ee7b-4c90-955c-c392576d2500')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-4125722a-ee7b-4c90-955c-c392576d2500 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4125722a-ee7b-4c90-955c-c392576d2500');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-60d3ea56-7639-408a-9986-6cf212be88da\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-60d3ea56-7639-408a-9986-6cf212be88da')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-60d3ea56-7639-408a-9986-6cf212be88da button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"id2label = {0: \\\"small\\\", 1: \\\"large\\\"}\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"intent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\uacc4\\uc815_\\uad00\\ub9ac\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\uacc4\\uc815\\uc744 \\uc644\\uc804\\ud788 \\uc0ad\\uc81c\\ud558\\ub824\\uba74 \\uc5b4\\ub5bb\\uac8c \\ud574\\uc57c \\ud558\\ub098\\uc694?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"complexity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"complex\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"suggested_model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"large\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["# 필요시 업로드할 수 있게 처리\n","csv_path = \"intent_dataset.csv\"\n","if not os.path.exists(csv_path):\n","    from google.colab import files\n","    print(\"upload intent_dataset.csv (or similarly named file)\")\n","    uploaded = files.upload()\n","    csv_path = list(uploaded.keys())[0]\n","\n","df = pd.read_csv(csv_path)\n","print(\"loaded\", len(df), \"rows; sample:\")\n","display(df.head())\n","# label encoding\n","label2id = {\"small\": 0, \"large\": 1}\n","id2label = {0: \"small\", 1: \"large\"}\n"]},{"cell_type":"markdown","metadata":{"id":"5n9LnloToIdx"},"source":["\n","### 데이터셋 전처리 및 PyTorch DataLoader 생성\n","\n","모델 학습을 위한 데이터 준비 과정을 수행합니다. 이 단계는 다음의 하위 과정으로 구성됩니다:\n","\n","PyTorch Dataset 클래스 정의: torch.utils.data.Dataset을 상속받아 커스텀 IntentDataset 클래스를 정의합니다. 이 클래스는 데이터를 토큰화하고 모델 입력 형식에 맞는 텐서(tensor)로 변환하는 역할을 합니다.\n","\n","데이터 분할: 전체 데이터셋을 sklearn의 train_test_split을 사용하여 학습(train), 검증(validation), 테스트(test) 세트로 8:1:1 비율로 계층적 분할(stratified split)합니다.\n","\n","데이터셋 및 DataLoader 인스턴스화: 분할된 각 데이터셋에 대해 IntentDataset과 DataLoader를 생성합니다. DataLoader는 배치(batch) 단위로 데이터를 모델에 효율적으로 공급하는 역할을 합니다."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"78j6gDBEWoIc","executionInfo":{"status":"ok","timestamp":1761619976535,"user_tz":-540,"elapsed":3,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"outputs":[],"source":["# [문제]: PyTorch의 Dataset 클래스를 상속받아 커스텀 데이터셋을 완성합니다.\n","class IntentDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_length=128):\n","        # 1. 레이블 데이터를 텐서로 변환하여 저장합니다.\n","        self.labels = torch.tensor(dataframe['label_id'].values, dtype=torch.long)\n","        # [문제 3]: __init__ 메서드에서 데이터프레임의 'text' 컬럼 전체를 한 번에 토크나이징하여\n","        # self.encodings에 저장합니다. 이는 학습 전, 미리 토크나이징을 진행하여 효율을 크게 높이는 중요한 처리 방식입니다.\n","        # truncation, padding, max_length, return_tensors='pt' 옵션을 사용해야 합니다.\n","        # [START CODE]\n","        self.encodings = tokenizer(\n","            list(dataframe['text']),\n","            truncation=True,\n","            padding='max_length',\n","            max_length=max_length,\n","            return_tensors='pt'\n","        )\n","        # [END CODE]\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        # [문제 4]: __getitem__ 메서드에서는 미리 토크나이징된 self.encodings에서\n","        # idx에 해당하는 데이터를 가져와야 합니다.\n","        # 올바른 텐서 조각(slice)을 가져와 'labels' 키에 레이블을 추가하여 딕셔너리 형태로 반환하세요.\n","        # [START CODE]\n","        item = {key: val[idx] for key, val in self.encodings.items()}\n","        item['labels'] = self.labels[idx]\n","        # [END CODE]\n","\n","        return item\n"]},{"cell_type":"markdown","metadata":{"id":"DLsp8CxwoLG-"},"source":["### 사전 학습된 모델 및 토크나이저 로드\n","HuggingFace Hub로부터 HuggingFaceTB/SmolLM2-135M-Instruct 모델을 로드합니다. 이 모델은 시퀀스 분류(Sequence Classification) 태스크를 수행할 수 있도록 AutoModelForSequenceClassification 클래스를 사용하여 초기화하며, num_labels와 레이블 맵(id2label, label2id)을 지정합니다. 해당 모델에 맞는 토크나이저 또한 AutoTokenizer를 통해 로드합니다."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":318,"referenced_widgets":["6cfae7210bfb4d3392483aa9032333aa","c29e8464844e4ed584541132a7a48faf","5357f7d1ba56450587c3ccd54134eb8a","91288d234d674572b2b558934a8b9268","ee43b8552d50480396c99f144d50f61b","b24143b5e7664cf1b58886f0b1a0ae08","5c624090d68045cf85a1d39493509228","eec764bed96c44f687b9fc3abe0904bc","338371678fa047318f8be470bd9d653b","cda8fd2a9cad4d00a20959dd10e7883f","742e58fc653f44fd8b2fa1abca4da109","112191af6d8e43e48c69cc648f380d66","59b1f486219a4b8c8645842da32e09fc","a40f3409b0c140db9fd370015bef766e","4b390987fd5d43018737d78fca608ca9","0db6466fb86b4db3b1ed9f7625ca03e9","63d75357b6854b3397c348d5242420d0","dc8cd408125445d28b8070f4ae727572","09d37e303189425f909e679f465db0e7","50c299fda8644d70bec8c28e5d014b52","14ef4fb1c26e45b3a694d0df0afc1d7b","47b55cfb74d74f04ba3e11bf97a35320","cafda429b72b42df8c39ccdf73768400","433d37bf8ec34f2cbd3b984b3f9a3699","19a6f7bf189746d0b1fd1ee0c733ee3a","b48643c3fa3b45a59f9805b75e89d6e9","479c594eb51b4b5b80590e0b6ad8d9f0","e4ef47ed2ff4492fa91cf3de248709ab","6b4256252eba443ba9c8ce60cddf8758","63bbb7fa92984d98ac3989f8dfb9c62b","3928ca7afb164c0fa4edf13722c0351f","4ccd3ca25dff4126856e0bef3a1b8ad4","96004aab8780467e89ad9c47d6307546","44469cab0da04fe2bda2115275b96698","932c303327f242f692e6f4e2ecaeb6d7","66b268ac3a3c438a99a93dfca74ca78b","4f4af4b0d9d24ea28560fa16b402a938","33e63509902344708481423e380844fe","1b26954460fe4194b514e1e2319b46db","dafad9d5466d4c878cdfd06173ad5cc8","aab1c8f4f4324cf5879b2a3026e7931f","c3f8ca971e8d4de3a7733e12626dad5e","95f22d9277f94621b9e4a690d4f884fe","ba02674069dd4d258c8300cab60be58a","c5887d18a0ea44dea2df87b1a238c06f","19c6d5739df74f75ac9b061a6183d4f6","bf0a6692df2e4ba48389caaeceb93a45","53da603b8f80425891e5ec3b5fb28b41","ce4a5f4faffc40d9b86bab5d4be91eb1","973ba5944e334accad91628b0eb59d98","81d45180fef0452c9cc0b9b03187e16a","2045df9be98e4a568afdd2e099b6d2b4","46ee9d77a2af4eaa9fa9ecded6ded938","2a8b400ec55f4ed6b4f6fd428e91ba7f","cd1576715ee34f3894c8cf6c6d6c9d41"]},"id":"j0rQY0NZVA-j","outputId":"d1372389-0d6b-4f73-e3e1-0321ccc3cd52","executionInfo":{"status":"ok","timestamp":1761619990758,"user_tz":-540,"elapsed":2566,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cfae7210bfb4d3392483aa9032333aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"112191af6d8e43e48c69cc648f380d66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cafda429b72b42df8c39ccdf73768400"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44469cab0da04fe2bda2115275b96698"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/655 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5887d18a0ea44dea2df87b1a238c06f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["train/val/test: 367 41 46\n"]}],"source":["\n","# train/val/test split (80/10/10)\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader\n","\n","\n","SEED = 42\n","\n","# ---------------------------\n","# 1. Binary 라벨 매핑\n","# ---------------------------\n","df['label_id'] = df['suggested_model'].map({'small': 0, 'large': 1})\n","\n","# ---------------------------\n","# [문제 5]: 전체 데이터프레임(df)을 학습+검증(train_val) 데이터와 테스트(test_df) 데이터로 9:1 비율로 분할합니다.\n","# stratify 옵션을 사용하여 레이블 비율을 유지해야 합니다.\n","# ---------------------------\n","# [START CODE]\n","train_val, test_df = train_test_split(\n","    df, test_size=0.1, stratify=df['label_id'], random_state=SEED\n",")\n","# [END CODE]\n","\n","# ---------------------------\n","# [문제 6]: 위에서 나눈 학습+검증(train_val) 데이터를 다시 학습(train_df)과 검증(val_df) 데이터로 분할합니다.\n","# 학습 데이터의 10%가 검증 데이터가 되도록 test_size를 조절해야 합니다.\n","# ---------------------------\n","# [START CODE]\n","train_df, val_df = train_test_split(\n","    train_val, test_size=0.1, stratify=train_val['label_id'], random_state=SEED\n",")\n","\n","# ---------------------------\n","# 3. Tokenizer\n","# ---------------------------\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","max_length = 128\n","# [END CODE]\n","\n","\n","# ---------------------------\n","# 4. Dataset\n","# ---------------------------\n","train_ds = IntentDataset(train_df, tokenizer, max_length=max_length)\n","val_ds   = IntentDataset(val_df, tokenizer, max_length=max_length)\n","test_ds  = IntentDataset(test_df, tokenizer, max_length=max_length)\n","\n","print(\"train/val/test:\", len(train_ds), len(val_ds), len(test_ds))\n","\n","# ---------------------------\n","# 5. DataLoader 연결\n","# ---------------------------\n","train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n","val_loader   = DataLoader(val_ds, batch_size=16)\n","test_loader  = DataLoader(test_ds, batch_size=16)"]},{"cell_type":"markdown","metadata":{"id":"gn7sGECXoOCX"},"source":["### LoRA(Low-Rank Adaptation) 설정 적용\n","파라미터 효율적 미세조정(PEFT) 기법인 LoRA를 모델에 적용합니다. LoraConfig를 통해 LoRA의 주요 하이퍼파라미터(r, lora_alpha, target_modules 등)를 설정합니다. get_peft_model 함수를 사용하여 기본 모델(base_model)에 LoRA 설정을 적용한 PEFT 모델을 생성합니다. print_trainable_parameters를 통해 전체 파라미터 대비 학습 대상 파라미터의 비율을 확인하여 LoRA가 얼마나 효율적인지 검증합니다."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"ucPj2hfyatRn","colab":{"base_uri":"https://localhost:8080/","height":170,"referenced_widgets":["a64fe9bdd64b47cf81eee94834eeb34a","15f89add4f6e4eee8595f80b410d2f29","9d292c676188472ea1f8a25d2e99ed60","f9a7a2b0dc2d47e290f5384d59e14223","f67fefa53d5b4000ac54299f49ffc01a","8c2e98256304450b90ea13fad5c02fe8","bf88f20bd3e2476892c37fb0a08cf128","cd9eede513854d28b07de803dd68c26e","84e94d13404f4069a7a38c3a02f9507b","fb23ec21455f4115ba73c6fc06d5b20b","116144f87280435faf824842e3d49f42","684ba2dfcaab4e2eaa671a2b30804cea","95070635c03c420cb068efe71d02eadc","fff88764f03d4e34bf4259082cece5f9","25d57a2a44954d619876a8105ed53638","394b1874c1fe4a509c13498257922455","21536b092b01482b8c283a898b4100e4","ffa33161c5bd412aa610fd67425636dc","a5d7167e144f4202afe586589811dc68","03282751d4554c7b89352d11a3230e0b","389963f7c20245868b37f558b579c4f6","4a49f6ef29014d4fa64d7c4c56c977d5"]},"executionInfo":{"status":"ok","timestamp":1761619996568,"user_tz":-540,"elapsed":5804,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"c69bd8b2-e516-4fb2-a586-5d8ff6f4a06f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/861 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a64fe9bdd64b47cf81eee94834eeb34a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"684ba2dfcaab4e2eaa671a2b30804cea"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at HuggingFaceTB/SmolLM2-135M-Instruct and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Loaded AutoModelForSequenceClassification successfully.\n","trainable params: 2,443,392 || all params: 136,959,552 || trainable%: 1.7840\n"]}],"source":["MODEL_NAME = \"HuggingFaceTB/SmolLM2-135M-Instruct\"  # 또는 사용하실 정확한 허브 네임 (변경 가능)\n","# 일부 사용자 업로드/비공식 model은 trust_remote_code=True 가 필요할 수 있음\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n","# [문제 7]: HuggingFace의 AutoModelForSequenceClassification을 사용하여 사전 학습된 모델을 로드합니다.\n","# num_labels, id2label, label2id를 파라미터로 전달하여 분류 태스크에 맞게 모델을 초기화해야 합니다.\n","# [START CODE]\n","base_model = AutoModelForSequenceClassification.from_pretrained(\n","    MODEL_NAME,\n","    num_labels=2,\n","    id2label=id2label,\n","    label2id=label2id,\n","    trust_remote_code=True\n",")\n","# [END CODE]\n","print(\"Loaded AutoModelForSequenceClassification successfully.\")\n","\n","# [문제 8]: LoRA 설정을 위한 LoraConfig를 정의합니다.\n","# r=8, lora_alpha=32, 타겟으로는 \"all-linear\"를 설정하고, 태스크 유형을 시퀀스 분류(\"SEQ_CLS\")로 지정합니다.\n","# [START CODE]\n","lora_config = LoraConfig(\n","    r=8,\n","    lora_alpha=32,\n","    target_modules=\"all-linear\",\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"SEQ_CLS\"   # 시퀀스 분류\n",")\n","# [END CODE]\n","\n","model = get_peft_model(base_model, lora_config)\n","model.print_trainable_parameters()  # 학습 가능한 파라미터 요약 확인\n"]},{"cell_type":"markdown","metadata":{"id":"-FP911NHkMqN"},"source":["### 모델 학습 실행\n","PyTorch를 사용한 표준적인 학습 루프(training loop)를 구현하여 모델을 학습시킵니다.\n","\n","준비: 모델을 GPU로 이동시키고, AdamW 옵티마이저와 CrossEntropyLoss 손실 함수를 정의합니다.\n","\n","학습 루프: 지정된 에포크(epoch) 수만큼 반복하며, 각 에포크마다 train_loader로부터 배치 단위로 데이터를 받아 순전파(forward pass), 손실 계산, 역전파(backward pass), 옵티마이저 스텝을 실행합니다.\n","\n","검증 루프: 각 에포크의 학습이 끝난 후, val_loader를 사용하여 검증 데이터셋에 대한 모델의 성능(손실 및 정확도)을 평가합니다. 이를 통해 과적합(overfitting) 여부를 모니터링합니다."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H6oxGL-mao-n","outputId":"c67612f6-87f4-4e0f-bc43-688a976398b6","executionInfo":{"status":"ok","timestamp":1761620062550,"user_tz":-540,"elapsed":65971,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["  suggested_model  label_id\n","0           small         0\n","1           small         0\n","2           small         0\n","3           large         1\n","4           large         1\n","5           large         1\n","6           small         0\n","7           small         0\n","8           large         1\n","9           small         0\n","Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 23/23 [00:13<00:00,  1.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4365, accuracy: 0.8204\n","Val   loss: 0.4367, accuracy: 0.8261\n","Epoch 2/5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 23/23 [00:11<00:00,  2.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3334, accuracy: 0.8453\n","Val   loss: 0.3560, accuracy: 0.8913\n","Epoch 3/5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 23/23 [00:13<00:00,  1.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.2114, accuracy: 0.9254\n","Val   loss: 0.2391, accuracy: 0.9130\n","Epoch 4/5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 23/23 [00:12<00:00,  1.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.1034, accuracy: 0.9641\n","Val   loss: 0.2835, accuracy: 0.9130\n","Epoch 5/5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 23/23 [00:11<00:00,  2.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.0630, accuracy: 0.9779\n","Val   loss: 0.2645, accuracy: 0.9130\n"]}],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","\n","# ---------------------------\n","# 1. label 처리: small=0, large=1\n","# ---------------------------\n","df['label_id'] = df['suggested_model'].map({'small': 0, 'large': 1})\n","print(df[['suggested_model','label_id']].head(10))\n","\n","\n","# ---------------------------\n","# 2. Train/Val/Test split\n","# ---------------------------\n","SEED = 42\n","train_val, test_df = train_test_split(df, test_size=0.1, stratify=df['label_id'], random_state=SEED)\n","train_df, val_df = train_test_split(train_val, test_size=0.1111111, stratify=train_val['label_id'], random_state=SEED)\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","max_length = 128\n","\n","train_ds = IntentDataset(train_df, tokenizer, max_length=max_length)\n","val_ds   = IntentDataset(val_df, tokenizer, max_length=max_length)\n","test_ds  = IntentDataset(test_df, tokenizer, max_length=max_length)\n","\n","train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n","val_loader   = DataLoader(val_ds, batch_size=16)\n","test_loader  = DataLoader(test_ds, batch_size=16)\n","\n","# ---------------------------\n","# 4. Model + optimizer\n","# ---------------------------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.train()\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)\n","criterion = torch.nn.CrossEntropyLoss()  # Binary classification도 CrossEntropyLoss 사용 가능\n","\n","# ---------------------------\n","# 5. Training Loop\n","# ---------------------------\n","num_epochs = 5\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch+1}/{num_epochs}\")\n","    epoch_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    for batch in tqdm(train_loader):\n","        optimizer.zero_grad()\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","        # [문제 9]: 모델의 순전파, 손실 계산, 역전파 과정을 완성합니다.\n","        # 1. 모델에 input_ids와 attention_mask를 전달하여 출력을 얻습니다.\n","        # 2. CrossEntropyLoss를 사용하여 모델의 출력(logits)과 실제 레이블(labels) 간의 손실을 계산합니다.\n","        # 3. 계산된 손실에 대해 역전파를 수행합니다.\n","        # 4. 옵티마이저를 사용하여 모델의 가중치를 업데이트합니다.\n","        # [START CODE]\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        loss = criterion(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","        # [END CODE]\n","\n","        epoch_loss += loss.item() * input_ids.size(0)\n","        preds = logits.argmax(dim=-1)\n","        correct += (preds == labels).sum().item()\n","        total += labels.size(0)\n","\n","    print(f\"Train loss: {epoch_loss/total:.4f}, accuracy: {correct/total:.4f}\")\n","\n","    # ---------------------------\n","    # Validation\n","    # ---------------------------\n","    model.eval()\n","    val_loss = 0\n","    val_correct = 0\n","    val_total = 0\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","            loss = criterion(logits, labels)\n","\n","            val_loss += loss.item() * input_ids.size(0)\n","            preds = logits.argmax(dim=-1)\n","            val_correct += (preds == labels).sum().item()\n","            val_total += labels.size(0)\n","\n","    print(f\"Val   loss: {val_loss/val_total:.4f}, accuracy: {val_correct/val_total:.4f}\")\n","    model.train()\n"]},{"cell_type":"markdown","metadata":{"id":"ilr5K_oJkWt8"},"source":["### 학습된 모델 가중치 저장\n","학습이 완료된 모델의 가중치를 저장하여 추후 재사용 및 배포가 가능하도록 합니다. 이 셀에서는 Google Drive를 마운트하여 Colab 세션이 종료된 후에도 파일이 유지되도록 합니다.\n","\n","LoRA 어댑터 저장: save_pretrained 메소드를 사용하여 학습된 LoRA 가중치(어댑터)만 별도로 저장합니다. 이는 용량이 작아 관리가 용이합니다.\n","\n","모델 병합 및 저장: PeftModel을 사용하여 기본 모델에 학습된 LoRA 어댑터를 병합(merge)합니다. 병합된 전체 모델은 추론(inference) 시 추가적인 처리 없이 바로 사용할 수 있는 상태가 되며, 이 모델을 Google Drive에 저장하여 영속성을 확보합니다.\n","\n","- 구글 Drive를 사용하지 않는다면, 모델 가중치를 저장해서 로컬등에 받아두어야 합니다."]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e604636c","outputId":"6b4608ba-1bf0-4248-b471-ecb7a9e3d7e0","executionInfo":{"status":"ok","timestamp":1761620067389,"user_tz":-540,"elapsed":4842,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Saved LoRA adapters to: peft_smollm2_adapters\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Merged model saved to /content/smollm2_merged_for_inference\n"]}],"source":["import os\n","\n","# adapter만 저장\n","peft_save_dir = \"peft_smollm2_adapters\"\n","model.save_pretrained(peft_save_dir)\n","print(\"Saved LoRA adapters to:\", peft_save_dir)\n","\n","# Define the path to save the model in Google Drive\n","drive_save_path = \"/content/drive/MyDrive/smollm2_merged_for_inference\"\n","\n","# Create the directory in Google Drive if it doesn't exist\n","os.makedirs(drive_save_path, exist_ok=True)\n","\n","# [문제 10]: 학습된 LoRA 어댑터를 기본 모델과 병합하여 배포용 모델을 생성합니다.\n","# merge_and_unload() 함수를 사용하세요.\n","# [START CODE]\n","# 배포/인퍼런스용으로 base + adapter 합치기\n","merged = PeftModel.from_pretrained(base_model, peft_save_dir)\n","merged_model = merged.merge_and_unload()\n","# [END CODE]\n","\n","# Save the merged model and tokenizer to Google Drive\n","merged_model.save_pretrained(drive_save_path)\n","tokenizer.save_pretrained(drive_save_path)\n","print(f\"Merged model saved to {drive_save_path}\")\n"]},{"cell_type":"markdown","metadata":{"id":"wAw2Dc_3kc9O"},"source":["### 분류 헤드(Classification Head) 가중치 저장\n","미세조정 과정에서 학습된 부분 중, 최종 분류를 담당하는 score 레이어(분류 헤드)의 가중치만 별도로 저장합니다. 이는 모델의 특정 부분만 분석하거나 다른 모델에 이식할 때 유용할 수 있습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MlDihsoMd2L2","outputId":"764e4b39-b4df-417f-8772-6b707825fcd0","executionInfo":{"status":"ok","timestamp":1760847169114,"user_tz":-540,"elapsed":20,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear(in_features=576, out_features=2, bias=False)"]},"metadata":{},"execution_count":20}],"source":["torch.save(merged_model.score.state_dict(), 'score_only.pt')\n","merged_model.score"]},{"cell_type":"markdown","metadata":{"id":"6Yc_zD1zkdgt"},"source":["### 저장된 모델을 이용한 추론(Inference) 테스트\n","저장된 병합 모델을 다시 불러와 실제 데이터에 대한 예측 성능을 테스트합니다.\n","\n","모델 로드: Google Drive에 저장된 모델과 토크나이저를 로드합니다. 로딩 실패 시, 기본 모델에 어댑터를 다시 적용하는 대체 로직이 포함되어 있습니다.\n","\n","예측 함수 정의: 텍스트를 입력받아 토큰화하고, 모델을 통해 예측된 레이블('small' 또는 'large')을 반환하는 predict_suggested_model 함수를 정의합니다.\n","\n","성능 검증: 사전에 정의된 테스트 문장들에 대해 예측을 수행하고, 예측 결과와 정답을 비교하여 모델이 새로운 데이터에 대해 얼마나 잘 일반화하는지 확인합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WpnWxAFaeXAa","outputId":"2d4e710c-cd9e-4015-a989-eef29f18bb40","executionInfo":{"status":"ok","timestamp":1760847169090,"user_tz":-540,"elapsed":2991,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Failed to load merged model from /content/smollm2_merged_for_inference: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/smollm2_merged_for_inference'. Use `repo_type` argument if needed.\n","LoRA adapter와 base model을 따로 로드하여 테스트합니다.\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at HuggingFaceTB/SmolLM2-135M-Instruct and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Loaded base model and adapter, then merged for inference.\n","\n","--- Test Predictions ---\n","'회원가입은 어떻게 하나요?'\n","  -> Complexity: simple, Correct Model: small, Predicted: small, Result: Correct\n","'주문한 상품의 배송 상태를 추적하고 싶습니다.'\n","  -> Complexity: simple, Correct Model: small, Predicted: large, Result: Incorrect\n","'결제 시 사용 가능한 할인 쿠폰이 있나요?'\n","  -> Complexity: simple, Correct Model: large, Predicted: large, Result: Correct\n","'로그인 시도 시 오류 코드가 발생하는데 해결 방법은 무엇인가요?'\n","  -> Complexity: complex, Correct Model: large, Predicted: large, Result: Correct\n","'주문 후 결제 수단을 변경할 수 있나요?'\n","  -> Complexity: complex, Correct Model: large, Predicted: large, Result: Correct\n","'이 제품의 상세 스펙과 사용 후기를 알고 싶습니다.'\n","  -> Complexity: complex, Correct Model: large, Predicted: large, Result: Correct\n"]}],"source":["# 셀 8: 모델 추론 예시\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from peft import PeftModel\n","\n","# 저장된 모델 경로\n","drive_save_path = \"/content/drive/MyDrive/smollm2_merged_for_inference\"\n","\n","# 저장된 merged model과 tokenizer 로드\n","try:\n","    inference_model = AutoModelForSequenceClassification.from_pretrained(drive_save_path)\n","    inference_tokenizer = AutoTokenizer.from_pretrained(drive_save_path)\n","    print(\"Merged model loaded successfully for inference.\")\n","except Exception as e:\n","    print(f\"Failed to load merged model from {drive_save_path}: {e}\")\n","    print(\"LoRA adapter와 base model을 따로 로드하여 테스트합니다.\")\n","    # 만약 merged model 로딩에 실패하면, base model에 adapter를 연결하여 사용\n","    base_model_path = \"HuggingFaceTB/SmolLM2-135M-Instruct\" # base model 경로\n","    base_model_inf = AutoModelForSequenceClassification.from_pretrained(\n","        base_model_path,\n","        num_labels=2,\n","        id2label=id2label, # 이전 셀에서 정의된 id2label 사용\n","        label2id=label2id, # 이전 셀에서 정의된 label2id 사용\n","        trust_remote_code=True\n","    )\n","    peft_save_dir = \"peft_smollm2_adapters\" # adapter 경로 (이전 셀에서 저장한 경로)\n","    inference_model = PeftModel.from_pretrained(base_model_inf, peft_save_dir)\n","    inference_model = inference_model.merge_and_unload() # 다시 merge 시도\n","    inference_tokenizer = AutoTokenizer.from_pretrained(base_model_path, trust_remote_code=True)\n","    print(\"Loaded base model and adapter, then merged for inference.\")\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","inference_model.to(device)\n","inference_model.eval() # 평가 모드\n","\n","# 예측 함수\n","def predict_suggested_model(text):\n","    inputs = inference_tokenizer(\n","        text,\n","        return_tensors=\"pt\",\n","        padding=True,\n","        truncation=True,\n","        max_length=128\n","    ).to(device)\n","    # [문제 11]: 모델 추론 과정을 완성합니다.\n","    # 1. torch.no_grad() 컨텍스트 내에서 모델의 순전파를 수행하여 출력을 얻습니다.\n","    # 2. 출력(logits)에서 가장 높은 값을 가진 인덱스를 찾아 예측 결과를 생성합니다.\n","    # [START CODE]\n","    with torch.no_grad():\n","        outputs = inference_model(**inputs)\n","        logits = outputs.logits\n","        predictions = torch.argmax(logits, dim=-1)\n","    # [END CODE]\n","\n","    predicted_id = predictions.item()\n","    predicted_label = inference_model.config.id2label[predicted_id]\n","    return predicted_label\n","\n","# 예시 테스트와 정답 비교\n","# 복잡도 및 suggested_model 정보는 예시 리스트에 직접 명시합니다.\n","test_sentences_with_info = [\n","    {\"text\": \"회원가입은 어떻게 하나요?\", \"complexity\": \"simple\", \"correct_model\": \"small\"}, # simple account\n","    {\"text\": \"주문한 상품의 배송 상태를 추적하고 싶습니다.\", \"complexity\": \"simple\", \"correct_model\": \"small\"}, # simple delivery\n","    {\"text\": \"결제 시 사용 가능한 할인 쿠폰이 있나요?\", \"complexity\": \"simple\", \"correct_model\": \"large\"}, # simple order (DEFAULT_ROUTER['주문_결제'] == False)\n","    {\"text\": \"로그인 시도 시 오류 코드가 발생하는데 해결 방법은 무엇인가요?\", \"complexity\": \"complex\", \"correct_model\": \"large\"}, # complex tech support\n","    {\"text\": \"주문 후 결제 수단을 변경할 수 있나요?\", \"complexity\": \"complex\", \"correct_model\": \"large\"}, # complex order\n","    {\"text\": \"이 제품의 상세 스펙과 사용 후기를 알고 싶습니다.\", \"complexity\": \"complex\", \"correct_model\": \"large\"} # complex product info\n","]\n","\n","print(\"\\n--- Test Predictions ---\")\n","for item in test_sentences_with_info:\n","    sentence = item['text']\n","    complexity = item['complexity']\n","    correct_label = item['correct_model']\n","\n","    predicted_model = predict_suggested_model(sentence)\n","\n","    is_correct = \"Correct\" if predicted_model == correct_label else \"Incorrect\"\n","\n","    print(f\"'{sentence}'\")\n","    print(f\"  -> Complexity: {complexity}, Correct Model: {correct_label}, Predicted: {predicted_model}, Result: {is_correct}\")"]},{"cell_type":"markdown","metadata":{"id":"X5GJU-1QqJ9I"},"source":["# 마치며 (Conclusion)\n","본 과제를 통해 LLM으로 합성 데이터셋을 구축하고 PEFT(LoRA) 기법으로 소형 모델을 최적화하는 엔드투엔드 파이프라인을 구현했습니다. 이 과정에서 데이터 증강 전략의 유효성과 파라미터 효율적 미세조정의 실용성을 확인하며, 기초적인 MLOps 워크플로우를 경험할 수 있었습니다. 여기서 개발된 모델은 자원 분배가 중요한 실제 서비스에 응용될 수 있으며, 향후 더 복잡한 분류 문제로 확장하거나 다양한 모델을 테스트하는 방향으로 발전시킬 수 있습니다. 이번 실습이 최신 AI 기술에 대한 깊이 있는 이해와 실용적 활용 능력을 다지는 계기가 되었기를 바랍니다."]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6cfae7210bfb4d3392483aa9032333aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c29e8464844e4ed584541132a7a48faf","IPY_MODEL_5357f7d1ba56450587c3ccd54134eb8a","IPY_MODEL_91288d234d674572b2b558934a8b9268"],"layout":"IPY_MODEL_ee43b8552d50480396c99f144d50f61b"}},"c29e8464844e4ed584541132a7a48faf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b24143b5e7664cf1b58886f0b1a0ae08","placeholder":"​","style":"IPY_MODEL_5c624090d68045cf85a1d39493509228","value":"tokenizer_config.json: "}},"5357f7d1ba56450587c3ccd54134eb8a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eec764bed96c44f687b9fc3abe0904bc","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_338371678fa047318f8be470bd9d653b","value":1}},"91288d234d674572b2b558934a8b9268":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cda8fd2a9cad4d00a20959dd10e7883f","placeholder":"​","style":"IPY_MODEL_742e58fc653f44fd8b2fa1abca4da109","value":" 3.76k/? [00:00&lt;00:00, 387kB/s]"}},"ee43b8552d50480396c99f144d50f61b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b24143b5e7664cf1b58886f0b1a0ae08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c624090d68045cf85a1d39493509228":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eec764bed96c44f687b9fc3abe0904bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"338371678fa047318f8be470bd9d653b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cda8fd2a9cad4d00a20959dd10e7883f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"742e58fc653f44fd8b2fa1abca4da109":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"112191af6d8e43e48c69cc648f380d66":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_59b1f486219a4b8c8645842da32e09fc","IPY_MODEL_a40f3409b0c140db9fd370015bef766e","IPY_MODEL_4b390987fd5d43018737d78fca608ca9"],"layout":"IPY_MODEL_0db6466fb86b4db3b1ed9f7625ca03e9"}},"59b1f486219a4b8c8645842da32e09fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63d75357b6854b3397c348d5242420d0","placeholder":"​","style":"IPY_MODEL_dc8cd408125445d28b8070f4ae727572","value":"vocab.json: "}},"a40f3409b0c140db9fd370015bef766e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_09d37e303189425f909e679f465db0e7","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_50c299fda8644d70bec8c28e5d014b52","value":1}},"4b390987fd5d43018737d78fca608ca9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14ef4fb1c26e45b3a694d0df0afc1d7b","placeholder":"​","style":"IPY_MODEL_47b55cfb74d74f04ba3e11bf97a35320","value":" 801k/? [00:00&lt;00:00, 29.3MB/s]"}},"0db6466fb86b4db3b1ed9f7625ca03e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63d75357b6854b3397c348d5242420d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc8cd408125445d28b8070f4ae727572":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09d37e303189425f909e679f465db0e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"50c299fda8644d70bec8c28e5d014b52":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"14ef4fb1c26e45b3a694d0df0afc1d7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47b55cfb74d74f04ba3e11bf97a35320":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cafda429b72b42df8c39ccdf73768400":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_433d37bf8ec34f2cbd3b984b3f9a3699","IPY_MODEL_19a6f7bf189746d0b1fd1ee0c733ee3a","IPY_MODEL_b48643c3fa3b45a59f9805b75e89d6e9"],"layout":"IPY_MODEL_479c594eb51b4b5b80590e0b6ad8d9f0"}},"433d37bf8ec34f2cbd3b984b3f9a3699":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4ef47ed2ff4492fa91cf3de248709ab","placeholder":"​","style":"IPY_MODEL_6b4256252eba443ba9c8ce60cddf8758","value":"merges.txt: "}},"19a6f7bf189746d0b1fd1ee0c733ee3a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_63bbb7fa92984d98ac3989f8dfb9c62b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3928ca7afb164c0fa4edf13722c0351f","value":1}},"b48643c3fa3b45a59f9805b75e89d6e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ccd3ca25dff4126856e0bef3a1b8ad4","placeholder":"​","style":"IPY_MODEL_96004aab8780467e89ad9c47d6307546","value":" 466k/? [00:00&lt;00:00, 24.2MB/s]"}},"479c594eb51b4b5b80590e0b6ad8d9f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4ef47ed2ff4492fa91cf3de248709ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b4256252eba443ba9c8ce60cddf8758":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63bbb7fa92984d98ac3989f8dfb9c62b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"3928ca7afb164c0fa4edf13722c0351f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4ccd3ca25dff4126856e0bef3a1b8ad4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96004aab8780467e89ad9c47d6307546":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44469cab0da04fe2bda2115275b96698":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_932c303327f242f692e6f4e2ecaeb6d7","IPY_MODEL_66b268ac3a3c438a99a93dfca74ca78b","IPY_MODEL_4f4af4b0d9d24ea28560fa16b402a938"],"layout":"IPY_MODEL_33e63509902344708481423e380844fe"}},"932c303327f242f692e6f4e2ecaeb6d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b26954460fe4194b514e1e2319b46db","placeholder":"​","style":"IPY_MODEL_dafad9d5466d4c878cdfd06173ad5cc8","value":"tokenizer.json: "}},"66b268ac3a3c438a99a93dfca74ca78b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aab1c8f4f4324cf5879b2a3026e7931f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3f8ca971e8d4de3a7733e12626dad5e","value":1}},"4f4af4b0d9d24ea28560fa16b402a938":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95f22d9277f94621b9e4a690d4f884fe","placeholder":"​","style":"IPY_MODEL_ba02674069dd4d258c8300cab60be58a","value":" 2.10M/? [00:00&lt;00:00, 57.4MB/s]"}},"33e63509902344708481423e380844fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b26954460fe4194b514e1e2319b46db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dafad9d5466d4c878cdfd06173ad5cc8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aab1c8f4f4324cf5879b2a3026e7931f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c3f8ca971e8d4de3a7733e12626dad5e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"95f22d9277f94621b9e4a690d4f884fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba02674069dd4d258c8300cab60be58a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5887d18a0ea44dea2df87b1a238c06f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_19c6d5739df74f75ac9b061a6183d4f6","IPY_MODEL_bf0a6692df2e4ba48389caaeceb93a45","IPY_MODEL_53da603b8f80425891e5ec3b5fb28b41"],"layout":"IPY_MODEL_ce4a5f4faffc40d9b86bab5d4be91eb1"}},"19c6d5739df74f75ac9b061a6183d4f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_973ba5944e334accad91628b0eb59d98","placeholder":"​","style":"IPY_MODEL_81d45180fef0452c9cc0b9b03187e16a","value":"special_tokens_map.json: 100%"}},"bf0a6692df2e4ba48389caaeceb93a45":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2045df9be98e4a568afdd2e099b6d2b4","max":655,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46ee9d77a2af4eaa9fa9ecded6ded938","value":655}},"53da603b8f80425891e5ec3b5fb28b41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a8b400ec55f4ed6b4f6fd428e91ba7f","placeholder":"​","style":"IPY_MODEL_cd1576715ee34f3894c8cf6c6d6c9d41","value":" 655/655 [00:00&lt;00:00, 79.5kB/s]"}},"ce4a5f4faffc40d9b86bab5d4be91eb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"973ba5944e334accad91628b0eb59d98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81d45180fef0452c9cc0b9b03187e16a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2045df9be98e4a568afdd2e099b6d2b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46ee9d77a2af4eaa9fa9ecded6ded938":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a8b400ec55f4ed6b4f6fd428e91ba7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd1576715ee34f3894c8cf6c6d6c9d41":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a64fe9bdd64b47cf81eee94834eeb34a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_15f89add4f6e4eee8595f80b410d2f29","IPY_MODEL_9d292c676188472ea1f8a25d2e99ed60","IPY_MODEL_f9a7a2b0dc2d47e290f5384d59e14223"],"layout":"IPY_MODEL_f67fefa53d5b4000ac54299f49ffc01a"}},"15f89add4f6e4eee8595f80b410d2f29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c2e98256304450b90ea13fad5c02fe8","placeholder":"​","style":"IPY_MODEL_bf88f20bd3e2476892c37fb0a08cf128","value":"config.json: 100%"}},"9d292c676188472ea1f8a25d2e99ed60":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd9eede513854d28b07de803dd68c26e","max":861,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84e94d13404f4069a7a38c3a02f9507b","value":861}},"f9a7a2b0dc2d47e290f5384d59e14223":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb23ec21455f4115ba73c6fc06d5b20b","placeholder":"​","style":"IPY_MODEL_116144f87280435faf824842e3d49f42","value":" 861/861 [00:00&lt;00:00, 93.8kB/s]"}},"f67fefa53d5b4000ac54299f49ffc01a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c2e98256304450b90ea13fad5c02fe8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf88f20bd3e2476892c37fb0a08cf128":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd9eede513854d28b07de803dd68c26e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84e94d13404f4069a7a38c3a02f9507b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fb23ec21455f4115ba73c6fc06d5b20b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"116144f87280435faf824842e3d49f42":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"684ba2dfcaab4e2eaa671a2b30804cea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_95070635c03c420cb068efe71d02eadc","IPY_MODEL_fff88764f03d4e34bf4259082cece5f9","IPY_MODEL_25d57a2a44954d619876a8105ed53638"],"layout":"IPY_MODEL_394b1874c1fe4a509c13498257922455"}},"95070635c03c420cb068efe71d02eadc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21536b092b01482b8c283a898b4100e4","placeholder":"​","style":"IPY_MODEL_ffa33161c5bd412aa610fd67425636dc","value":"model.safetensors: 100%"}},"fff88764f03d4e34bf4259082cece5f9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5d7167e144f4202afe586589811dc68","max":269060552,"min":0,"orientation":"horizontal","style":"IPY_MODEL_03282751d4554c7b89352d11a3230e0b","value":269060552}},"25d57a2a44954d619876a8105ed53638":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_389963f7c20245868b37f558b579c4f6","placeholder":"​","style":"IPY_MODEL_4a49f6ef29014d4fa64d7c4c56c977d5","value":" 269M/269M [00:04&lt;00:00, 92.3MB/s]"}},"394b1874c1fe4a509c13498257922455":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21536b092b01482b8c283a898b4100e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffa33161c5bd412aa610fd67425636dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5d7167e144f4202afe586589811dc68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03282751d4554c7b89352d11a3230e0b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"389963f7c20245868b37f558b579c4f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a49f6ef29014d4fa64d7c4c56c977d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}